[
  {
	"id": 1,
	"title": "Introduction to Large Language Models and Transformer Architecture",
	"description": "Large language models are a type of neural network that can be trained to perform a variety of natural language processing tasks.",
	"slug": "introduction-to-large-language-models-and-transformer-architecture",
	"thumbnail": "https://miro.medium.com/v2/resize:fit:1256/format:webp/1*zlj8N1mdfX-OLfxDqrzmig.png",
	"view_count": 0,
	"created_at": "2024-03-03T16:22:48.255Z",
	"updated_at": "2024-03-03T16:22:48.255Z",
	"user_id": 1,
	"is_published": true,
	"tags": "nlp, transformer, llms"
  },
  {
	"id": 2,
	"title": "Preparing Text Data for Transformers: Tokenization, Mapping and Padding",
	"description": "Transformers require a specific input format, which includes tokenization, mapping and padding. This article explains how to prepare text data for transformer models.",
	"slug": "preparing-text-data-for-transformers-tokenization-mapping-and-padding",
	"thumbnail": "https://miro.medium.com/v2/resize:fit:1400/1*yM9GYw49kIFf3bKp2Eg2AQ.png",
	"view_count": 0,
	"created_at": "2024-03-03T22:22:48.255Z",
	"updated_at": "2024-03-03T22:22:48.255Z",
	"user_id": 1,
	"is_published": true,
	"tags": "nlp, transformer, tokenization, padding, mapping, llms"
  },
  {
	"id": 3,
	"title": "Cloudflare ditched NGINX and open-sourced Pingora",
	"description": "Cloudflare has open-sourced Pingora, a high-performance HTTP server that is designed to be a drop-in replacement for NGINX.",
	"slug": "cloudflare-ditched-nginx-and-open-sourced-pingora",
	"thumbnail": "https://blog.cloudflare.com/content/images/2024/02/Rock-crab-OG.png",
	"view_count": 0,
	"created_at": "2024-03-04T14:11:48",
	"updated_at": "2024-03-04T14:11:48",
	"user_id": 1,
	"is_published": true,
	"tags": "cloudflare, nginx, pingora, proxy"
  },
  {
	"id": 4,
	"title": "Fine-Tuning Large Language Models (LLMs)",
	"description": "We start by introducing key FT concepts and techniques, then finish with a concrete example of how to fine-tune a model (locally) using Python and Hugging Faceâ€™s software ecosystem.",
	"slug": "fine-tuning-large-language-models-llms",
	"thumbnail": "https://blog.monsterapi.ai/content/images/2023/07/Fine-tunning.png",
	"view_count": 0,
	"created_at": "2024-03-04T16:56:48",
	"updated_at": "2024-03-04T16:56:48",
	"user_id": 1,
	"is_published": true,
	"tags": "nlp, transformer, llms, fine-tuning, peft, lora"
  }, 
  {
	"id": 5,
	"title": "Retrieval Augmented Generation (RAG)",
	"description": "Retrieval augmented generation (RAG) is an architecture that provides the most relevant and contextually-important proprietary, private or dynamic data to your Generative AI application's large language model (LLM) when it is performing tasks to enhance its accuracy and performance.",
	"slug": "retrieval-augmented-generation-rag",
	"thumbnail": "https://miro.medium.com/v2/resize:fit:1400/1*kSkeaXRvRzbJ9SrFZaMoOg.png",
	"view_count": 0,
	"created_at": "2024-03-04T23:56:48",
	"updated_at": "2024-03-04T23:56:48",
	"user_id": 1,
	"is_published": true,
	"tags": "nlp, llms, rag, retrieval, generation, generativeai"
  }
]